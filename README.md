We present MATE, a masked LM assembling text edit, designed to derive the maximum benefit from the ideas of FELIX, a flexible text-editing approach for text generation by decomposing the text-editing task into two sub-tasks: tagging and insertion which are trained independently. 
In our work, text representations are shared between the tagging and insertion models using a single shared encoder, performed a joint training framework instead of training them separately, and self-supervised data generation approach for pre-training step is presented to solve the low resource problem specially in tagging sub-task.
